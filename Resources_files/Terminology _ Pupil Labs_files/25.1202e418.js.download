(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{304:function(e,t,i){"use strict";i.r(t);var a=i(0),r=Object(a.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h1",{attrs:{id:"terminology"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#terminology","aria-hidden":"true"}},[e._v("#")]),e._v(" Terminology")]),e._v(" "),i("h2",{attrs:{id:"world"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#world","aria-hidden":"true"}},[e._v("#")]),e._v(" World")]),e._v(" "),i("p",[e._v("The term "),i("code",[e._v("world")]),e._v(" generally refers to the subject's field of view. Sometimes it is used\nin combination with other terms:")]),e._v(" "),i("ul",[i("li",[i("strong",[e._v("World Camera")]),e._v(": Physical scene camera that captures the subject's field of view.")]),e._v(" "),i("li",[i("strong",[e._v("World Process")]),e._v(": Application process responsible for processing the "),i("em",[e._v("world camera")]),e._v("\nvideo stream and "),i("a",{attrs:{href:"#gaze-positions"}},[i("em",[e._v("gaze mapping")])]),e._v(".")]),e._v(" "),i("li",[i("strong",[e._v("World Window")]),e._v(": The main Pupil Capture window; previews the result of the "),i("em",[e._v("world process")])]),e._v(" "),i("li",[i("strong",[e._v("World Coordinate System")]),e._v(": Refers to the "),i("a",{attrs:{href:"#coordinate-system"}},[i("em",[e._v("Coordinate System")])]),e._v(" of the "),i("em",[e._v("world camera")]),e._v(".")])]),e._v(" "),i("h2",{attrs:{id:"eye"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#eye","aria-hidden":"true"}},[e._v("#")]),e._v(" Eye")]),e._v(" "),i("p",[e._v("The term "),i("code",[e._v("eye")]),e._v(" is always used in combination with a different term that specifies the context:")]),e._v(" "),i("ul",[i("li",[i("strong",[e._v("Eye ID")]),e._v(": "),i("code",[e._v("0")]),e._v(" or "),i("code",[e._v("1")]),e._v("; identifies the right and left eyes.")]),e._v(" "),i("li",[i("strong",[e._v("Eye Camera")]),e._v(": Physical camera capturing the subject's eye. There can be one or two\neye cameras, depending on your setup.")]),e._v(" "),i("li",[i("strong",[e._v("Eye Process")]),e._v(": Application process responsible for processing the "),i("em",[e._v("eye camera")]),e._v(" video\nstream and "),i("a",{attrs:{href:"#pupil-positions"}},[i("em",[e._v("pupil detection")])]),e._v(".")]),e._v(" "),i("li",[i("strong",[e._v("Eye Window")]),e._v(": Previews the result of the "),i("em",[e._v("eye process")]),e._v(".")]),e._v(" "),i("li",[i("strong",[e._v("Eye Coordinate System")]),e._v(": Refers to the "),i("a",{attrs:{href:"#coordinate-system"}},[i("em",[e._v("Coordinate System")])]),e._v(" of the "),i("em",[e._v("eye camera")]),e._v(".")]),e._v(" "),i("li",[i("strong",[e._v("Eye Model")]),e._v(": Result of the "),i("em",[e._v("3d pupil detection")]),e._v(".")])]),e._v(" "),i("h2",{attrs:{id:"pupil-positions"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#pupil-positions","aria-hidden":"true"}},[e._v("#")]),e._v(" Pupil Positions")]),e._v(" "),i("p",[e._v("Alternatively: "),i("em",[e._v("Pupil Data")]),e._v(". Output of the "),i("em",[e._v("pupil detection")]),e._v(". Location of the pupil\nwithin the "),i("em",[e._v("eye coordinate system")]),e._v(".")]),e._v(" "),i("ul",[i("li",[i("strong",[e._v("Pupil Detection")]),e._v(": Process of detecting the pupil within the "),i("em",[e._v("eye camera")]),e._v(" video stream.")]),e._v(" "),i("li",[i("strong",[e._v("2d Pupil Detection")]),e._v(": Attempts to find a 2d ellipse that fits the pupil within a given "),i("em",[e._v("eye")]),e._v(" image.\n"),i("a",{attrs:{href:"https://arxiv.org/pdf/1405.0006.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Reference paper"),i("OutboundLink")],1),e._v(".")]),e._v(" "),i("li",[i("strong",[e._v("3d Pupil Detection")]),e._v(": Uses a series of 2D ellipses to fit a 3d "),i("em",[e._v("eye model")]),e._v(".\n"),i("a",{attrs:{href:"https://www.researchgate.net/profile/Lech_Swirski/publication/264658852_A_fully-automatic_temporal_approach_to_single_camera_glint-free_3D_eye_model_fitting/links/53ea3dbf0cf28f342f418dfe/A-fully-automatic-temporal-approach-to-single-camera-glint-free-3D-eye-model-fitting.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Reference paper"),i("OutboundLink")],1),e._v(".")])]),e._v(" "),i("h2",{attrs:{id:"gaze-positions"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#gaze-positions","aria-hidden":"true"}},[e._v("#")]),e._v(" Gaze Positions")]),e._v(" "),i("p",[e._v("Alternatively: "),i("em",[e._v("Gaze Data")]),e._v(". Output of the "),i("em",[e._v("gaze estimation")]),e._v(". Location of the subject's\ngaze within the "),i("em",[e._v("world coordinate system")]),e._v(".")]),e._v(" "),i("ul",[i("li",[i("strong",[e._v("Gaze Estimation")]),e._v(": Process of mapping a Pupil Position from the "),i("em",[e._v("eye coordinate system")]),e._v("\nto the "),i("em",[e._v("world coordinate system")]),e._v(".")])]),e._v(" "),i("h2",{attrs:{id:"confidence"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#confidence","aria-hidden":"true"}},[e._v("#")]),e._v(" Confidence")]),e._v(" "),i("p",[e._v("Quality assessment of the "),i("em",[e._v("pupil detection")]),e._v(" for a given "),i("em",[e._v("eye")]),e._v(" image.")]),e._v(" "),i("ul",[i("li",[i("code",[e._v("0.0")]),e._v(" means that the pupil could not be detected.")]),e._v(" "),i("li",[i("code",[e._v("1.0")]),e._v(" highest possible value; the pupil was detected with very high certainty.")])]),e._v(" "),i("p",[i("em",[e._v("Gaze data")]),e._v(" inherits the "),i("em",[e._v("confidence")]),e._v(" value from the "),i("em",[e._v("pupil data")]),e._v(" it was based on.")]),e._v(" "),i("h2",{attrs:{id:"calibration"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#calibration","aria-hidden":"true"}},[e._v("#")]),e._v(" Calibration")]),e._v(" "),i("p",[e._v("Process of understanding the relationship between "),i("em",[e._v("pupil positions")]),e._v(" and their\ncorresponding "),i("em",[e._v("gaze position")]),e._v(" within the "),i("em",[e._v("world coordinate stystem")]),e._v(".")]),e._v(" "),i("p",[e._v("During the "),i("em",[e._v("calibration")]),e._v(" process the subject is asked to fixate a list of target\n(reference) locations within the "),i("em",[e._v("world camera")]),e._v("'s field of view. The Pupil Core software\ncollects these reference locations and "),i("em",[e._v("pupil data")]),e._v(" during the calibration. Afterwards,\nit correlates them in time and calculates a mapping function that is used to estimate\nthe gaze for future pupil data.")]),e._v(" "),i("h2",{attrs:{id:"timing"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#timing","aria-hidden":"true"}},[e._v("#")]),e._v(" Timing")]),e._v(" "),i("p",[e._v("Pupil Core software uses timestamps with 64-bit floating point values. Their unit is\n"),i("em",[e._v("seconds")]),e._v(". Pupil Core differentiates between to clocks:")]),e._v(" "),i("ul",[i("li",[i("em",[e._v("System Time")]),e._v(": Returns devices current date time (not precise).")]),e._v(" "),i("li",[i("em",[e._v("Pupil Time")]),e._v(": Synchronized clock used for time measurements (precise).")])]),e._v(" "),i("h3",{attrs:{id:"epoch"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#epoch","aria-hidden":"true"}},[e._v("#")]),e._v(" Epoch")]),e._v(" "),i("blockquote",[i("p",[e._v("The epoch is the point where the time starts [...]. For Unix,\nthe epoch is January 1, 1970, 00:00:00 (UTC).")])]),e._v(" "),i("ul",[i("li",[i("a",{attrs:{href:"https://docs.python.org/3/library/time.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://docs.python.org/3/library/time.html"),i("OutboundLink")],1)])]),e._v(" "),i("h3",{attrs:{id:"system-time"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#system-time","aria-hidden":"true"}},[e._v("#")]),e._v(" System Time")]),e._v(" "),i("p",[e._v("The current date time of the device running the Pupil Core software. Uses the "),i("em",[e._v("Unix epoch")]),e._v(".\nThe "),i("em",[e._v("system time")]),e._v(" clock is not guaranteed to be monotonicly increasing since it is\nsubject to the devices network clock synchronization.")]),e._v(" "),i("h3",{attrs:{id:"pupil-time"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#pupil-time","aria-hidden":"true"}},[e._v("#")]),e._v(" Pupil Time")]),e._v(" "),i("p",[e._v("A precise monotonicly increasing clock for time measurements. Pupil Core software uses\nit to timestamp all its generated data. This clock's "),i("em",[e._v("epoch")]),e._v(" is arbitrary. A fixed offset\ncan be applied between recordings to synchronize multiple devices running Pupil Core\nsoftware.")]),e._v(" "),i("h2",{attrs:{id:"coordinate-system"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#coordinate-system","aria-hidden":"true"}},[e._v("#")]),e._v(" Coordinate System")]),e._v(" "),i("p",[e._v("There are three coordinate systems for each camera:")]),e._v(" "),i("ul",[i("li",[i("strong",[e._v("2D Image Space")]),e._v(":\n"),i("ul",[i("li",[e._v("origin: top left")]),e._v(" "),i("li",[e._v("unit: pixels")]),e._v(" "),i("li",[e._v("includes lens distortion")]),e._v(" "),i("li",[e._v("bounds:\n"),i("ul",[i("li",[i("code",[e._v("x: [0, <image width>], y: [0, <image height>]")])])])]),e._v(" "),i("li",[e._v("example: "),i("code",[e._v("image shape: (800, 400), location: (400, 200)")]),e._v(" (image center)")])])]),e._v(" "),i("li",[i("strong",[e._v("2D Normalised Space")]),e._v(":\n"),i("ul",[i("li",[e._v("origin: bottom left")]),e._v(" "),i("li",[e._v("unit: image width/height")]),e._v(" "),i("li",[e._v("includes lens distortion")]),e._v(" "),i("li",[e._v("equivalent to "),i("em",[e._v("2d image space")]),e._v(", normalised")]),e._v(" "),i("li",[e._v("bounds:\n"),i("ul",[i("li",[i("code",[e._v("x: [0, 1], y: [0, 1]")])])])]),e._v(" "),i("li",[e._v("example: "),i("code",[e._v("(0.5, 0.5)")]),e._v(" (image center)")])])]),e._v(" "),i("li",[i("strong",[e._v("3D Camera Space")]),e._v(":\n"),i("ul",[i("li",[e._v("origin: center")]),e._v(" "),i("li",[e._v("unit: mm")]),e._v(" "),i("li",[e._v("does not includes lens distortion")]),e._v(" "),i("li",[e._v("bounds:\n"),i("ul",[i("li",[i("code",[e._v("x: [0, <image width>], y: [0, <image height>]")])])])]),e._v(" "),i("li",[e._v("example: "),i("code",[e._v("(0, 0, 1)")]),e._v(" (image center)")])])])]),e._v(" "),i("p",[i("a",{attrs:{href:"https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Reference"),i("OutboundLink")],1),e._v(".\nYou can use the "),i("em",[e._v("Camera Intrinsics")]),e._v(" to project a "),i("em",[e._v("3d camera location")]),e._v(" to "),i("em",[e._v("2d pixel location")]),e._v(", and vice versa.")]),e._v(" "),i("h2",{attrs:{id:"camera-intrinsics"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#camera-intrinsics","aria-hidden":"true"}},[e._v("#")]),e._v(" Camera Intrinsics")]),e._v(" "),i("p",[e._v("The "),i("em",[e._v("camera intrinsics")]),e._v(" contain "),i("a",{attrs:{href:"https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("camera matrix and lens distortion information"),i("OutboundLink")],1),e._v(".\nThey are used in "),i("em",[e._v("3d gaze mapping")]),e._v(" to correctly transform "),i("em",[e._v("3d pupil data")]),e._v(" to "),i("em",[e._v("3d gaze data")]),e._v(".")]),e._v(" "),i("p",[e._v("The Pupil Core software provides default camera intrinsics for all official Pupil Core\ncameras. It is recommended to run the "),i("router-link",{attrs:{to:"/core/software/pupil-capture/#camera-intrinsics-estimation"}},[e._v("Camera Intrinsics Estimation")]),e._v("\nfor your Pupil Core "),i("em",[e._v("world")]),e._v(" camera after receiving it. Each camera is slightly different\nand running the estimation locally will result in slightly more precise gaze mapping.")],1)])}),[],!1,null,null,null);t.default=r.exports}}]);